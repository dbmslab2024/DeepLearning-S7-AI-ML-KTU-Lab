10-line step-by-step algorithm for your ID3 decision tree program, suitable for a lab manual:

1.  **Initialize Data:** Define the training dataset (e.g., 'PlayTennis' data) with features and a target variable.
2.  **Define `entropy` Function:** Implement `entropy(target_col)` to measure data impurity.
3.  **Define `info_gain` Function:** Implement `info_gain(data, attribute, target)` to calculate information gain for an attribute.
4.  **Define `ID3` Function:** Create `ID3(data, original_data, features, target)` for recursive tree building.
5.  **`ID3` Logic:** In `ID3`, select the best feature (highest info gain), create a node, and recurse for each feature value.
6.  **`ID3` Base Cases:** Handle uniform target values, empty datasets, or no remaining features.
7.  **Define `predict` Function:** Implement `predict(query, tree)` to traverse the tree for classification.
8.  **Build Tree:** Call `ID3` with the initial data, features, and target to construct the decision tree.
9.  **Get User Input:** Prompt the user for values for a new sample's features.
10. **Predict & Display:** Use `predict` to classify the user's sample and print the result.