{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necesary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:14.280659Z",
     "iopub.status.busy": "2022-01-03T11:00:14.28039Z",
     "iopub.status.idle": "2022-01-03T11:00:14.286624Z",
     "shell.execute_reply": "2022-01-03T11:00:14.285879Z",
     "shell.execute_reply.started": "2022-01-03T11:00:14.280628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 11:54:15.533197: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-29 11:54:15.543937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-29 11:54:15.556553: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-29 11:54:15.560438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-29 11:54:15.569797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-29 11:54:16.220341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dense, Input, Embedding\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:14.708694Z",
     "iopub.status.busy": "2022-01-03T11:00:14.708255Z",
     "iopub.status.idle": "2022-01-03T11:00:15.341744Z",
     "shell.execute_reply": "2022-01-03T11:00:15.340236Z",
     "shell.execute_reply.started": "2022-01-03T11:00:14.708662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "3        ted  what we really mean is that they're bad at not...   \n",
       "4  indic2012  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/cs-ai-21/Prince/DeepLearning-S7-AI-ML-KTU-Lab/code/exp11/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:15.34361Z",
     "iopub.status.busy": "2022-01-03T11:00:15.343345Z",
     "iopub.status.idle": "2022-01-03T11:00:15.363925Z",
     "shell.execute_reply": "2022-01-03T11:00:15.363006Z",
     "shell.execute_reply.started": "2022-01-03T11:00:15.343574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting sources\n",
    "data['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:16.099028Z",
     "iopub.status.busy": "2022-01-03T11:00:16.098702Z",
     "iopub.status.idle": "2022-01-03T11:00:16.503248Z",
     "shell.execute_reply": "2022-01-03T11:00:16.502471Z",
     "shell.execute_reply.started": "2022-01-03T11:00:16.098987Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mcountplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.countplot(x='source', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:16.505328Z",
     "iopub.status.busy": "2022-01-03T11:00:16.504881Z",
     "iopub.status.idle": "2022-01-03T11:00:16.513251Z",
     "shell.execute_reply": "2022-01-03T11:00:16.512215Z",
     "shell.execute_reply.started": "2022-01-03T11:00:16.50529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Total data: \",data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:17.134807Z",
     "iopub.status.busy": "2022-01-03T11:00:17.134082Z",
     "iopub.status.idle": "2022-01-03T11:00:17.163304Z",
     "shell.execute_reply": "2022-01-03T11:00:17.162602Z",
     "shell.execute_reply.started": "2022-01-03T11:00:17.134769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# selcting data with source ted\n",
    "data = data[data.source == 'ted']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:17.851152Z",
     "iopub.status.busy": "2022-01-03T11:00:17.850774Z",
     "iopub.status.idle": "2022-01-03T11:00:17.87377Z",
     "shell.execute_reply": "2022-01-03T11:00:17.87245Z",
     "shell.execute_reply.started": "2022-01-03T11:00:17.851118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# checking null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:18.152733Z",
     "iopub.status.busy": "2022-01-03T11:00:18.152477Z",
     "iopub.status.idle": "2022-01-03T11:00:18.254342Z",
     "shell.execute_reply": "2022-01-03T11:00:18.253589Z",
     "shell.execute_reply.started": "2022-01-03T11:00:18.152704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# checking duplicated data\n",
    "isDuplicated = data.duplicated().any()\n",
    "if isDuplicated:\n",
    "    total_duplicates = data.duplicated().sum()\n",
    "    print(\"Total duplicate rows are: \",total_duplicates)\n",
    "    data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:18.946709Z",
     "iopub.status.busy": "2022-01-03T11:00:18.946328Z",
     "iopub.status.idle": "2022-01-03T11:00:18.960666Z",
     "shell.execute_reply": "2022-01-03T11:00:18.959935Z",
     "shell.execute_reply.started": "2022-01-03T11:00:18.946677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## sampling 20000 rows randomly\n",
    "data = data.sample(n = 20000, random_state = 31)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:25.02464Z",
     "iopub.status.busy": "2022-01-03T11:00:25.024034Z",
     "iopub.status.idle": "2022-01-03T11:00:25.111316Z",
     "shell.execute_reply": "2022-01-03T11:00:25.110612Z",
     "shell.execute_reply.started": "2022-01-03T11:00:25.024601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## changing uppercase to lowercase\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: x.lower())\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove quotes\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:25.851815Z",
     "iopub.status.busy": "2022-01-03T11:00:25.851549Z",
     "iopub.status.idle": "2022-01-03T11:00:26.084273Z",
     "shell.execute_reply": "2022-01-03T11:00:26.083524Z",
     "shell.execute_reply.started": "2022-01-03T11:00:25.851784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "to_exclude = set(string.punctuation) # Set of all special characters\n",
    "print(\"punctuations to exclude:: \",to_exclude)\n",
    "# Remove all the special characters\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in to_exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:35.363274Z",
     "iopub.status.busy": "2022-01-03T11:00:35.362992Z",
     "iopub.status.idle": "2022-01-03T11:00:35.700307Z",
     "shell.execute_reply": "2022-01-03T11:00:35.699527Z",
     "shell.execute_reply.started": "2022-01-03T11:00:35.363242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from string import digits\n",
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: x.strip())\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.strip())\n",
    "data['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "data['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:42.165191Z",
     "iopub.status.busy": "2022-01-03T11:00:42.16491Z",
     "iopub.status.idle": "2022-01-03T11:00:42.181792Z",
     "shell.execute_reply": "2022-01-03T11:00:42.180853Z",
     "shell.execute_reply.started": "2022-01-03T11:00:42.165142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## adding start and end token to the target sentence\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: \"START_ \" + x + \" _END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:47.084537Z",
     "iopub.status.busy": "2022-01-03T11:00:47.083978Z",
     "iopub.status.idle": "2022-01-03T11:00:47.14273Z",
     "shell.execute_reply": "2022-01-03T11:00:47.142062Z",
     "shell.execute_reply.started": "2022-01-03T11:00:47.084498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## counting length of english and hindi sentence\n",
    "data['english_length'] = data['english_sentence'].apply(lambda x: len(x.split(' ')))\n",
    "data['hindi_length'] = data['hindi_sentence'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:48.561201Z",
     "iopub.status.busy": "2022-01-03T11:00:48.560906Z",
     "iopub.status.idle": "2022-01-03T11:00:48.572223Z",
     "shell.execute_reply": "2022-01-03T11:00:48.571375Z",
     "shell.execute_reply.started": "2022-01-03T11:00:48.561152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Maximum length of English Sentence: \", max(data['english_length']))\n",
    "print(\"Maximum length of Hindi Sentence: \",max(data['hindi_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:49.808021Z",
     "iopub.status.busy": "2022-01-03T11:00:49.807741Z",
     "iopub.status.idle": "2022-01-03T11:00:49.922114Z",
     "shell.execute_reply": "2022-01-03T11:00:49.921202Z",
     "shell.execute_reply.started": "2022-01-03T11:00:49.80799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in data['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in data['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)\n",
    "            \n",
    "\n",
    "print(\"toral english words: \",len(all_eng_words))\n",
    "print('total hind words: ',len(all_hindi_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:51.516695Z",
     "iopub.status.busy": "2022-01-03T11:00:51.516274Z",
     "iopub.status.idle": "2022-01-03T11:00:51.529003Z",
     "shell.execute_reply": "2022-01-03T11:00:51.528122Z",
     "shell.execute_reply.started": "2022-01-03T11:00:51.516655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## using only sentence with length less than 20\n",
    "mask1 = data['english_length'] < 21\n",
    "mask2 = data['hindi_length'] < 21\n",
    "data = data[mask1 & mask2]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:52.590182Z",
     "iopub.status.busy": "2022-01-03T11:00:52.589861Z",
     "iopub.status.idle": "2022-01-03T11:00:52.601117Z",
     "shell.execute_reply": "2022-01-03T11:00:52.599956Z",
     "shell.execute_reply.started": "2022-01-03T11:00:52.590137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(data['hindi_length']))\n",
    "print(\"maximum length of English Sentence \",max(data['english_length']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:00:54.490354Z",
     "iopub.status.busy": "2022-01-03T11:00:54.488285Z",
     "iopub.status.idle": "2022-01-03T11:00:54.510089Z",
     "shell.execute_reply": "2022-01-03T11:00:54.509416Z",
     "shell.execute_reply.started": "2022-01-03T11:00:54.4903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:01:01.341423Z",
     "iopub.status.busy": "2022-01-03T11:01:01.340882Z",
     "iopub.status.idle": "2022-01-03T11:01:01.34532Z",
     "shell.execute_reply": "2022-01-03T11:01:01.344232Z",
     "shell.execute_reply.started": "2022-01-03T11:01:01.341382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:01:26.463706Z",
     "iopub.status.busy": "2022-01-03T11:01:26.46345Z",
     "iopub.status.idle": "2022-01-03T11:01:26.481718Z",
     "shell.execute_reply": "2022-01-03T11:01:26.480843Z",
     "shell.execute_reply.started": "2022-01-03T11:01:26.463677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "print(\"Token for accelerating is: \",input_token_index['accelerating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:01:26.815507Z",
     "iopub.status.busy": "2022-01-03T11:01:26.815051Z",
     "iopub.status.idle": "2022-01-03T11:01:26.830545Z",
     "shell.execute_reply": "2022-01-03T11:01:26.829838Z",
     "shell.execute_reply.started": "2022-01-03T11:01:26.815474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "print(\"Character for toker 50 is: \",reverse_input_char_index[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:01:28.387738Z",
     "iopub.status.busy": "2022-01-03T11:01:28.387478Z",
     "iopub.status.idle": "2022-01-03T11:01:28.403095Z",
     "shell.execute_reply": "2022-01-03T11:01:28.402246Z",
     "shell.execute_reply.started": "2022-01-03T11:01:28.387707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# splitting data\n",
    "X_, y_ = data['english_sentence'], data['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size = 0.2,random_state=42)\n",
    "print(\"Total number of training data: \",X_train.shape[0])\n",
    "print(\"Toral number of testing data: \",X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:01:28.725665Z",
     "iopub.status.busy": "2022-01-03T11:01:28.725311Z",
     "iopub.status.idle": "2022-01-03T11:02:28.702561Z",
     "shell.execute_reply": "2022-01-03T11:02:28.701851Z",
     "shell.execute_reply.started": "2022-01-03T11:01:28.725632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 300\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:02:28.704469Z",
     "iopub.status.busy": "2022-01-03T11:02:28.70419Z",
     "iopub.status.idle": "2022-01-03T11:02:28.713996Z",
     "shell.execute_reply": "2022-01-03T11:02:28.713224Z",
     "shell.execute_reply.started": "2022-01-03T11:02:28.704434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:02:28.71584Z",
     "iopub.status.busy": "2022-01-03T11:02:28.715125Z",
     "iopub.status.idle": "2022-01-03T11:02:28.726061Z",
     "shell.execute_reply": "2022-01-03T11:02:28.7253Z",
     "shell.execute_reply.started": "2022-01-03T11:02:28.715793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length_src = 20\n",
    "max_length_tar = 20 \n",
    "\n",
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:02:28.728405Z",
     "iopub.status.busy": "2022-01-03T11:02:28.727983Z",
     "iopub.status.idle": "2022-01-03T11:02:28.737982Z",
     "shell.execute_reply": "2022-01-03T11:02:28.737305Z",
     "shell.execute_reply.started": "2022-01-03T11:02:28.728368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:04:23.07077Z",
     "iopub.status.busy": "2022-01-03T11:04:23.070067Z",
     "iopub.status.idle": "2022-01-03T11:13:44.174311Z",
     "shell.execute_reply": "2022-01-03T11:13:44.17236Z",
     "shell.execute_reply.started": "2022-01-03T11:04:23.070733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:03:29.964155Z",
     "iopub.status.busy": "2022-01-03T11:03:29.963885Z",
     "iopub.status.idle": "2022-01-03T11:03:31.297253Z",
     "shell.execute_reply": "2022-01-03T11:03:31.296502Z",
     "shell.execute_reply.started": "2022-01-03T11:03:29.964124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = tf.keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:03:31.299362Z",
     "iopub.status.busy": "2022-01-03T11:03:31.299104Z",
     "iopub.status.idle": "2022-01-03T11:03:31.304444Z",
     "shell.execute_reply": "2022-01-03T11:03:31.302602Z",
     "shell.execute_reply.started": "2022-01-03T11:03:31.299328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:13:53.189521Z",
     "iopub.status.busy": "2022-01-03T11:13:53.189253Z",
     "iopub.status.idle": "2022-01-03T11:13:53.726422Z",
     "shell.execute_reply": "2022-01-03T11:13:53.725627Z",
     "shell.execute_reply.started": "2022-01-03T11:13:53.189492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:14:12.48124Z",
     "iopub.status.busy": "2022-01-03T11:14:12.48096Z",
     "iopub.status.idle": "2022-01-03T11:14:13.025671Z",
     "shell.execute_reply": "2022-01-03T11:14:13.024377Z",
     "shell.execute_reply.started": "2022-01-03T11:14:12.481207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-03T11:03:23.546914Z",
     "iopub.status.idle": "2022-01-03T11:03:23.547867Z",
     "shell.execute_reply": "2022-01-03T11:03:23.547279Z",
     "shell.execute_reply.started": "2022-01-03T11:03:23.547215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:04:05.896963Z",
     "iopub.status.busy": "2022-01-03T11:04:05.896458Z",
     "iopub.status.idle": "2022-01-03T11:04:06.172343Z",
     "shell.execute_reply": "2022-01-03T11:04:06.171595Z",
     "shell.execute_reply.started": "2022-01-03T11:04:05.896924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-03T11:04:11.218037Z",
     "iopub.status.busy": "2022-01-03T11:04:11.217267Z",
     "iopub.status.idle": "2022-01-03T11:04:11.651166Z",
     "shell.execute_reply": "2022-01-03T11:04:11.649101Z",
     "shell.execute_reply.started": "2022-01-03T11:04:11.217989Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "k = k + 1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 200079,
     "sourceId": 441417,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
